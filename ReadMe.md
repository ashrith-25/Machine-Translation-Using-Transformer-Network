# Transformer for NMT

* The dataset used is the IIT Bombay parallel corpus.
* The transformer was trained on 300000 Translations.
* This implementation uses Tensorflow.
* The model is hosted at hugging face spaces at - https://huggingface.co/spaces/sarat-chowdary/Translation-Eng-to-Hin 
* The model performs reasonablly well and can be improved with more training epochs and hyperparameter tuning.
* This implementation strips all punctuation which can give meaning to sentences in certain instances.

