# Transformer for NMT

* The dataset used is the IIT Bombay parallel corpus.
* The transformer was trained on 300000 Translations.
* This implementation uses Tensorflow.
* The model is hosted at hugging face spaces at - https://huggingface.co/spaces/sarat-chowdary/Translation-Eng-to-Hin 
* The model performs reasonablly well and can be improved with more training epochs and hyperparameter tuning.
* This implementation strips all punctuation which can give meaning to sentences in certain instances.
* This shows itself in the translations displayed below.
* Check out the following images to view the results


![Screenshot (11)](https://user-images.githubusercontent.com/88512953/219960202-5c3be7ce-10e5-436e-add6-9aa311be30a4.png)
![Screenshot (12)](https://user-images.githubusercontent.com/88512953/219960256-e18ae40c-800b-4eb7-bdd1-5ddd2fd81729.png)
![Screenshot (13)](https://user-images.githubusercontent.com/88512953/219960290-45c5e25f-b96f-4c24-aa80-caf82979e00e.png)
